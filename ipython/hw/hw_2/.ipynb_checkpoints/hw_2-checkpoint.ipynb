{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Aman Kumar Mahato\n",
    "\n",
    "Student Netid: akm533\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a Training Set and Training a Decision Tree\n",
    "This is a hands-on task where we build a predictive model using Decision Trees discussed in class. For this part, we will be using the data in `cell2cell_data.csv`.\n",
    "\n",
    "These historical data consist of 39,859 customers: 19,901 customers that churned (i.e., left the company) and 19,958 that did not churn (see the `\"churndep\"` variable). Here are the data set's 11 possible predictor variables for churning behavior: \n",
    "\n",
    "```\n",
    "Pos.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "```\n",
    "\n",
    "The 12th column, the dependent variable `\"churndep\"`, equals 1 if the customer churned, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data and prepare it for modeling. Note that the features are already processed for you, so the only thing needed here is split the data into training and testing. Use pandas to create two data frames: train_df and test_df, where train_df has 80% of the data chosen uniformly at random without replacement (test_df should have the other 20%). Also, make sure to write your own code to do the splits. You may use any random() function numpy but DO NOT use the data splitting functions from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31887, 12) (7972, 12) (39859, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "#loading data to the data frame\n",
    "data = pd.read_csv('/Users/amanmahato/Desktop/DataScienceCourse/ipython/hw/hw_2/data/Cell2Cell_data.csv', \n",
    "                  names = [\"revenue\", \"outcalls\", \"incalls\", \"months\", \"eqpdays\", \"webcap\", \"marryyes\", \"travel\", \"pcown\", \"creditcd\", \"retcalls\", \"churndep\"])\n",
    "#Creating data frames: train_df=80% of data and test_df=20% of data\n",
    "rand = list(range(len(data)))\n",
    "div= int(len(data)*0.8) #0.8 for 80% of data\n",
    "rd.shuffle(rand)\n",
    "train_df_index=rand[:div]\n",
    "test_df_index=rand[div:]\n",
    "#iloc works on the positions in the index\n",
    "train_df=data.iloc[train_df_index,:]\n",
    "test_df=data.iloc[test_df_index,:]\n",
    "print (train_df.shape, test_df.shape,data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. If we had to, how would we prove to ourselves or a colleague that our data was indeed randomly sampled on X? And by prove, I mean empirically, not just showing this person our code. Don't actually do the work, just describe in your own words a test you could here. Hint: think about this in terms of selection bias and use notes from our 2nd lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "To Prove that our data was randomly sampled on X, we need to prove that each instance of sample is independent of the instances of the overall population from which the random data were generated. Now from the above logic, the way I have selected and split the data is based on the index value which is nothing but the list of all the numbers starting from 0 upto 39858 and then this list of index is shuffled randomly and then the first 80% of the rows were assigned to the train_df and the remaining 20% to the test_df. Here we can see these index values in the index table are unique and independent of any other index values. Hence, it can be concluded that both the test_df and train_df is randomly selected and are independent. The other way it can be thaught of is runining the above script millions of times and then compare the index in the train_df and test_df and then show that there exist now relationship with the previosu values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Now build and train a decision tree classifier using `DecisionTreeClassifier()` [(manual page)](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) on train_df to predict the `\"churndep\"` target variable. Make sure to use `criterion='entropy'` when instantiating an instance of `DecisionTreeClassifier()`. For all other settings you should use all of the default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#function to build decision tree\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(train_df.drop('churndep',1),train_df['churndep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the resulting model from 2.2, show a bar plot of feature names and their feature importance (hint: check the attributes of the `DecisionTreeClassifier()` object directly in IPython or check the manual!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11c568e80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEtCAYAAAAbeVcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab68d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "#feature_importances_ : array of shape = [n_features]\n",
    "ax.bar(np.arange(11), clf.feature_importances_, color='b')\n",
    "ax.set_xticks(np.arange(len(clf.feature_importances_)))\n",
    "ax.set_xticklabels(train_df.drop('churndep',1).columns.values,rotation=90)\n",
    "plt.title('Feature Importance from Data Frame')\n",
    "ax.set_ylabel('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Is the relationship between the top 3 most important features (as measured here) negative or positive? If your marketing director asked you to explain the top 3 drivers of churn, how would you interpret the relationship between these 3 features and the churn outcome?  What \"real-life\" connection can you draw between each variable and churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0111745727195\n",
      "-0.0382539753695\n",
      "0.112488553705\n"
     ]
    }
   ],
   "source": [
    "# Code/answer here\n",
    "#From the above bar plot, the three most important features are revenue, outcalls and eqpdays. \n",
    "#Looking at the correlation coefficient to find the relationship between these important features and churndep\n",
    "print(np.corrcoef(train_df['revenue'],train_df['churndep'])[1][0])\n",
    "print(np.corrcoef(train_df['outcalls'],train_df['churndep'])[1][0])\n",
    "print(np.corrcoef(train_df['eqpdays'],train_df['churndep'])[1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, the correlation coefficient are: \n",
    "revenue and churndep-->negative\n",
    "outcalls and churndep-->negative\n",
    "eqpdays and churndep-->positive\n",
    "This can be interpreted as when the relatioship between revenue and churndep is as when revenue increases, churndep \n",
    "decreases and similar relation goes with outcalls and churndep ie. both the revenue and outcalls are inversely related\n",
    "with churndep but the relationship between eqpdays and churndep is direct which means if eqpdays increases, churndep\n",
    "will increase linearly. Hence, to my marketing director, I will explain that to increase the revenue, less people should churn and more people should make more outcalls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Using the classifier built in 2.2, try predicting `\"churndep\"` on both the train_df and test_df data sets. What is the accuracy on each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is:  0.538384345208\n",
      "Accuracy on Training Data is:  0.999843196287\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "#Confusion Matrix is used to describle the performance of classification model here\n",
    "#confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)---Syntax\n",
    "cm_test = confusion_matrix(clf.predict(test_df.drop('churndep',axis=1)),test_df['churndep'])\n",
    "cm_train = confusion_matrix(clf.predict(train_df.drop('churndep',axis=1)),train_df['churndep'])\n",
    "acc_test = (cm_test[0][0]+cm_test[1][1])/float(sum(sum(cm_test)))\n",
    "acc_train = (cm_train[0][0]+cm_train[1][1])/float(sum(sum(cm_train)))\n",
    "print (\"Accuracy on Test Data is: \",acc_test)\n",
    "print (\"Accuracy on Training Data is: \",acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Finding a Good Decision Tree\n",
    "The default options for your decision tree may not be optimal. We need to analyze whether tuning the parameters can improve the accuracy of the classifier.  For the following options `min_samples_split` and `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Generate a list of 10 values of each for the parameters mim_samples_split and min_samples_leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 102 202 302 402 502 602 702 802 902] [  1  21  41  61  81 101 121 141 161 181]\n"
     ]
    }
   ],
   "source": [
    "min_samples_split_values = np.arange(2,1000,100)\n",
    "min_samples_leaf_values = np.arange(1,200,20)\n",
    "print (min_samples_split_values,min_samples_leaf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Explain in words your reasoning for choosing the above ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "I have taken two corner cases here and then equally spaced the interval. The node split value is set at 2 and the default number at which the particular node to be considered as leaf is 1. The upper case was considered in the virtue of fact that there is equal split between the target variables. This leads to tree overfitting but before that tree expands enough to give the good accuracy. If we keep increasing this value, the tree might suffer from underfitting there by reducing the accuracy.\n",
    "In case of leaves, 200 was considered considering the fact that less number will make the entropy close to 0 and the we get the better Decision Tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. For each combination of values in 3.1 (there should be 100), build a new classifier and check the classifier's accuracy on the test data. Plot the test set accuracy for these options. Use the values of `min_samples_split` as the x-axis and generate a new series (line) for each of `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating dictionary of lists\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "return_results = defaultdict(list)\n",
    "#calculating the accuracy for each tree and storing in the dictionary return_results\n",
    "for leaf_value in min_samples_leaf_values:\n",
    "    for split_value in min_samples_split_values:\n",
    "        clf = DecisionTreeClassifier(criterion='entropy',min_samples_split=split_value, min_samples_leaf=leaf_value)\n",
    "        clf = clf.fit(train_df.drop('churndep',1),train_df['churndep'])\n",
    "        return_results[leaf_value].append(accuracy_score(test_df['churndep'],clf.predict(test_df.drop('churndep',1))))\n",
    "      \n",
    "# plotting the results\n",
    "fig = plt.figure() \n",
    "ax=fig.add_subplot(111)\n",
    "for key,value in results.items():\n",
    "    plt.plot(min_samples_split_values,value, label='Min Leaf Value: {}'.format(key))\n",
    "ax.set_xlabel('Min Sample Split')\n",
    "ax.set_ylabel('Test Set Accuracy')\n",
    "plt.title('Holdout Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Which configuration returns the best accuracy? What is this accuracy? (Note, if you don't see much variation in the test set accuracy across values of min_samples_split or min_samples_leaf, try redoing the above steps with a different range of values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to find the best accuracy\n",
    "def best_Accuracy(best):\n",
    "    maximum=0\n",
    "    leaf_Max=0\n",
    "    split_Max=0\n",
    "    # finding maximum in each list\n",
    "    for key, val in return_results.items():  \n",
    "        if maximum < max(val):\n",
    "            maximum = max(val)\n",
    "            leaf_Max = key\n",
    "            #Creating the split value again\n",
    "            split_Max = val.index(max(val))*(1000/(10+2))\n",
    "    return maximum,leaf_Max,split_Max\n",
    "best = best_Accuracy(return_results)\n",
    "print (\"Accuracy: \",best[0])\n",
    "print (\"Leaves: \",best[1])\n",
    "print (\"Splits: \",int(best[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. If you were working for a marketing department, how would you use your churn production model in a real business environment? Explain why churn prediction might be good for the business and how one might improve churn by using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "In a real business environemnt, the objective for any business is to have the greater revenue and churn prediction can help the business know what are the factors which are causing the business loose the customers and reduce the revenue. This model also gives the most important features which has direct effect on the churndep and thus knowing these factors, the business can work on those features which has negative correlation with the churn to reduce the churn. For an instance, in this case, the churndep is directly corelated with eqpdays and thus the business can work on increasing the eqpdays to reduce the churndep and can introduce some incentives to make the people use their current equipment.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
